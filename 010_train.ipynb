{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "##### Copyright (C) Microsoft Corporation.  \n",
    "see license file for details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/azureml-share/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AZUREML_NATIVE_SHARE_DIRECTORY mapping to host dir is set by _nativeSharedDirectory_ in .compute file \n",
    "\n",
    "import os\n",
    "try:\n",
    "    amlWBSharedDir = os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']    \n",
    "except:\n",
    "    amlWBSharedDir = ''\n",
    "    print('not using aml services?')\n",
    "    \n",
    "amlWBSharedDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Azure Machine Learning data collector to log various metrics\n",
    "from azureml.logging import get_azureml_logger\n",
    "logger = get_azureml_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Azure Machine Learning history magic to control history collection\n",
    "# History is off by default, options are \"on\", \"off\", or \"show\"\n",
    "# %azureml history on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import utlity functions\n",
    "\n",
    "import sys, os\n",
    "paths_to_append = [os.path.join(os.getcwd(), os.path.join(*(['Code',  'src'])))]\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import azure_chestxray_utils\n",
    "# import azure_chestxray_keras_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file path variables \n",
    "# paths are tipically container level dirs mapped to a host dir for data persistence.\n",
    "\n",
    "prj_consts = azure_chestxray_utils.chestxray_consts()\n",
    "\n",
    "data_base_input_dir=os.path.join(amlWBSharedDir, \n",
    "                                 os.path.join(*(prj_consts.BASE_INPUT_DIR_list)))\n",
    "data_base_output_dir=os.path.join(amlWBSharedDir, \n",
    "                                  os.path.join(*(prj_consts.BASE_OUTPUT_DIR_list)))  \n",
    "\n",
    "\n",
    "# data used for training\n",
    "nih_chest_xray_data_dir=os.path.join(data_base_input_dir, \n",
    "                                     os.path.join(*(prj_consts.ChestXray_IMAGES_DIR_list)))\n",
    "\n",
    "data_partitions_dir=os.path.join(data_base_output_dir, \n",
    "                                os.path.join(*(prj_consts.DATA_PARTITIONS_DIR_list)))  \n",
    "partition_path = os.path.join(data_partitions_dir, 'partition14_unormalized_cleaned.pickle')\n",
    "label_path = os.path.join(data_partitions_dir,'labels14_unormalized_cleaned.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/azureml-share/chestxray/output/weights_tmpdir'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "weights_dir = os.path.join(data_base_output_dir, os.path.join(*(prj_consts.MODEL_WEIGHTS_DIR_list))) \n",
    "!mkdir -p {weights_dir}\n",
    "weights_dir\n",
    "!ls -l {weights_dir}\n",
    "\n",
    "# weights_path = os.path.join(\n",
    "#     weights_dir, \n",
    "#     prj_consts.PRETRAINED_DENSENET201_IMAGENET_CHESTXRAY_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "ia.seed(1)\n",
    "\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras_contrib.applications.densenet import DenseNetImageNet121\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing purpose, we just run 1 epoch. It will take around 25 mins to run for one epoch using 2 K80 GPUs and it is usually needed to run around 30~50 epochs for the model to get converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make force_restart = False if you continue a previous train session, make it True to start from scratch\n",
    "force_restart = False\n",
    "\n",
    "initial_lr = 0.001\n",
    "resized_height = 224\n",
    "resized_width = 224\n",
    "# resized_height = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_HEIGHT\n",
    "# resized_width = prj_consts.CHESTXRAY_MODEL_EXPECTED_IMAGE_WIDTH\n",
    "num_channel = 3\n",
    "num_classes = 14\n",
    "epochs = 1 #200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: number of GPUs available in the system\n",
    "\n",
    "    \"\"\"\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "# get number of available GPUs\n",
    "num_gpu = len(get_available_gpus())\n",
    "\n",
    "# keras multi_gpu_model slices the data to different GPUs. see https://keras.io/utils/#multi_gpu_model for more details.\n",
    "batch_size = 48 * num_gpu\n",
    "\n",
    "\n",
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_lib.list_local_devices()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras multi-gpu model, so we need to make sure the batch_size is divisible by num_gpu.\n",
    "\n",
    "# multi GPU model checkpoint. copied from https://github.com/keras-team/keras/issues/8463\n",
    "class MultiGPUCheckpointCallback(Callback):\n",
    "\n",
    "    def __init__(self, filepath, base_model, monitor='val_loss', verbose=0,\n",
    "                 save_best_only=False, save_weights_only=False,\n",
    "                 mode='auto', period=1):\n",
    "        super(MultiGPUCheckpointCallback, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.period = period\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch + 1, self.monitor, self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.base_model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.base_model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.base_model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.base_model.save(filepath, overwrite=True)\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),  # horizontal flips\n",
    "    iaa.Affine(rotate=(-15, 15)),  # random rotate image\n",
    "    iaa.Affine(scale=(0.8, 1.1)),  # randomly scale the image\n",
    "], random_order=True)  # apply augmenters in random order\n",
    "\n",
    "\n",
    "# generator for train and validation data\n",
    "# use the Sequence class per issue https://github.com/keras-team/keras/issues/1638\n",
    "class DataGenSequence(Sequence):\n",
    "    def __init__(self, labels, image_file_index, current_state):\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.img_file_index = image_file_index\n",
    "        self.current_state = current_state\n",
    "        self.len = len(self.img_file_index) // self.batch_size\n",
    "        print(\"for DataGenSequence\", current_state, \"total rows are:\", len(self.img_file_index), \", len is\", self.len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"loading data segmentation\", idx)\n",
    "        # make sure each batch size has the same amount of data\n",
    "        current_batch = self.img_file_index[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, resized_height, resized_width, num_channel))\n",
    "        y = np.empty((self.batch_size, num_classes))\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(nih_chest_xray_data_dir, image_name)\n",
    "            # loading data\n",
    "\n",
    "            img = cv2.resize(cv2.imread(path), (resized_height, resized_width)).astype(np.float32)\n",
    "            X[i, :, :, :] = img\n",
    "            y[i, :] = labels[image_name]\n",
    "\n",
    "            # only do random flipping in training status\n",
    "        if self.current_state == 'train':\n",
    "            x_augmented = seq.augment_images(X)\n",
    "        else:\n",
    "            x_augmented = X\n",
    "\n",
    "        return x_augmented, y\n",
    "\n",
    "\n",
    "# loss function\n",
    "def unweighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_true: true labels\n",
    "        y_pred: predicted labels\n",
    "\n",
    "    Returns: the sum of binary cross entropy loss across all the classes\n",
    "\n",
    "    \"\"\"\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "\n",
    "    Returns: a model with specified weights\n",
    "\n",
    "    \"\"\"\n",
    "    # define the model, use pre-trained weights for image_net\n",
    "    base_model = DenseNetImageNet121(input_shape=(224, 224, 3),\n",
    "                                     weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(14, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 2 GPUs\n",
      "Downloading data from https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-121-32-no-top.h5\n",
      "33202176/33199896 [==============================] - 8s 0us/step\n",
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "if num_gpu > 1:\n",
    "    print(\"using\", num_gpu, \"GPUs\")\n",
    "    # build model\n",
    "    with tf.device('/cpu:0'):\n",
    "        model_single_gpu = build_model()\n",
    "    # model_single_gpu.load_weights(weights_path)\n",
    "\n",
    "    # convert to multi-gpu model\n",
    "    model_multi_gpu = multi_gpu_model(model_single_gpu, gpus=num_gpu)\n",
    "    model_checkpoint = MultiGPUCheckpointCallback(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        model_single_gpu, monitor='val_loss', save_weights_only=False)\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"using single GPU\")\n",
    "    model_multi_gpu = build_model()\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(weights_dir, 'azure_chest_xray_14_weights_712split_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "        monitor='val_loss', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for DataGenSequence train total rows are: 68508 , len is 713\n",
      "for DataGenSequence validation total rows are: 9495 , len is 98\n",
      "Epoch 1/1\n",
      "713/713 [==============================] - 1275s 2s/step - loss: 214.9958 - val_loss: 225.4705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e8955d5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 10 * num_gpu\n",
    "\n",
    "model_multi_gpu.compile(optimizer=Adam(lr=initial_lr), loss=unweighted_binary_crossentropy)\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "callbacks = [model_checkpoint, reduce_lr_on_plateau]\n",
    "\n",
    "with open(label_path, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(partition_path, 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "\n",
    "model_multi_gpu.fit_generator(generator=DataGenSequence(labels, partition['train'], current_state='train'),\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              workers=num_workers,\n",
    "                              # max_queue_size=32,\n",
    "                              # shuffle=False,\n",
    "                              validation_data=DataGenSequence(labels, partition['valid'], current_state='validation')\n",
    "                              # validation_steps=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to html .\\Code\\02_Model\\010_train.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_chestxray_lung_disease gpucomputecontext",
   "language": "python",
   "name": "azure_chestxray_lung_disease_gpucomputecontext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
